{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyautogen in c:\\users\\kamathshweta\\appdata\\local\\anaconda3\\lib\\site-packages (0.2.35)\n",
      "Requirement already satisfied: diskcache in c:\\users\\kamathshweta\\appdata\\local\\anaconda3\\lib\\site-packages (from pyautogen) (5.6.3)\n",
      "Requirement already satisfied: docker in c:\\users\\kamathshweta\\appdata\\local\\anaconda3\\lib\\site-packages (from pyautogen) (7.1.0)\n",
      "Requirement already satisfied: flaml in c:\\users\\kamathshweta\\appdata\\local\\anaconda3\\lib\\site-packages (from pyautogen) (2.2.0)\n",
      "Requirement already satisfied: numpy<2,>=1.17.0 in c:\\users\\kamathshweta\\appdata\\local\\anaconda3\\lib\\site-packages (from pyautogen) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.3 in c:\\users\\kamathshweta\\appdata\\local\\anaconda3\\lib\\site-packages (from pyautogen) (1.43.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\kamathshweta\\appdata\\local\\anaconda3\\lib\\site-packages (from pyautogen) (23.2)\n",
      "Requirement already satisfied: pydantic!=2.6.0,<3,>=1.10 in c:\\users\\kamathshweta\\appdata\\local\\anaconda3\\lib\\site-packages (from pyautogen) (2.8.2)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\kamathshweta\\appdata\\local\\anaconda3\\lib\\site-packages (from pyautogen) (0.21.0)\n",
      "Requirement already satisfied: termcolor in c:\\users\\kamathshweta\\appdata\\local\\anaconda3\\lib\\site-packages (from pyautogen) (2.4.0)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\kamathshweta\\appdata\\local\\anaconda3\\lib\\site-packages (from pyautogen) (0.7.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\kamathshweta\\appdata\\local\\anaconda3\\lib\\site-packages (from openai>=1.3->pyautogen) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\kamathshweta\\appdata\\local\\anaconda3\\lib\\site-packages (from openai>=1.3->pyautogen) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\kamathshweta\\appdata\\local\\anaconda3\\lib\\site-packages (from openai>=1.3->pyautogen) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\kamathshweta\\appdata\\local\\anaconda3\\lib\\site-packages (from openai>=1.3->pyautogen) (0.5.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\kamathshweta\\appdata\\local\\anaconda3\\lib\\site-packages (from openai>=1.3->pyautogen) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\kamathshweta\\appdata\\local\\anaconda3\\lib\\site-packages (from openai>=1.3->pyautogen) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\kamathshweta\\appdata\\local\\anaconda3\\lib\\site-packages (from openai>=1.3->pyautogen) (4.11.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\kamathshweta\\appdata\\local\\anaconda3\\lib\\site-packages (from pydantic!=2.6.0,<3,>=1.10->pyautogen) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\kamathshweta\\appdata\\local\\anaconda3\\lib\\site-packages (from pydantic!=2.6.0,<3,>=1.10->pyautogen) (2.20.1)\n",
      "Requirement already satisfied: pywin32>=304 in c:\\users\\kamathshweta\\appdata\\local\\anaconda3\\lib\\site-packages (from docker->pyautogen) (305.1)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\kamathshweta\\appdata\\local\\anaconda3\\lib\\site-packages (from docker->pyautogen) (2.32.2)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\kamathshweta\\appdata\\local\\anaconda3\\lib\\site-packages (from docker->pyautogen) (2.2.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\kamathshweta\\appdata\\local\\anaconda3\\lib\\site-packages (from tiktoken->pyautogen) (2023.10.3)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\kamathshweta\\appdata\\local\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai>=1.3->pyautogen) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\kamathshweta\\appdata\\local\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=1.3->pyautogen) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\kamathshweta\\appdata\\local\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=1.3->pyautogen) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\kamathshweta\\appdata\\local\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.3->pyautogen) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kamathshweta\\appdata\\local\\anaconda3\\lib\\site-packages (from requests>=2.26.0->docker->pyautogen) (2.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\kamathshweta\\appdata\\local\\anaconda3\\lib\\site-packages (from tqdm>4->openai>=1.3->pyautogen) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyautogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%restart` not found.\n"
     ]
    }
   ],
   "source": [
    "#restartkernel()\n",
    "#%restart - k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_VERSION\"] = \"2023-12-01-preview\"\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"XXXX\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] =  \"XXXX\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_deployment=\"XXXX\",  # or your deployment\n",
    "    api_version=\"2023-06-01-preview\",  # or your api version\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "llm_config = {\n",
    "    \"timeout\": 600,\n",
    "    \"config_list\": [{\"model\":\"sk-demo1\", \"api_key\": \"XXXX\", \"base_url\": \"XXXX\"}],\n",
    "    \"temperature\": 0,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "Give me a summary of this article: (\"C:\\Users\\kamathshweta\\Downloads\\Test2.txt\")\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "To summarize the article, I will first read the content of the file. I'll provide you with a Python script to do that.\n",
      "\n",
      "# filename: read_article.py\n",
      "```python\n",
      "# Read the content of the specified file and print it\n",
      "file_path = r\"C:\\Users\\kamathshweta\\Downloads\\Test2.txt\"\n",
      "\n",
      "try:\n",
      "    with open(file_path, 'r', encoding='utf-8') as file:\n",
      "        content = file.read()\n",
      "        print(content)\n",
      "except Exception as e:\n",
      "    print(f\"An error occurred: {e}\")\n",
      "```\n",
      "\n",
      "Please execute this script to read the content of the article.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\u001b[0m\n",
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: \n",
      "AutoGen is an open-source programming framework for building AI agents and facilitating cooperation among multiple agents to solve tasks. AutoGen aims to provide an easy-to-use and flexible framework for accelerating development and research on agentic AI, like PyTorch for Deep Learning. It offers features such as agents that can converse with other agents, LLM and tool use support, autonomous and human-in-the-loop workflows, and multi-agent conversation patterns.\n",
      "Multi-Agent Conversation Framework\n",
      "Autogen enables the next-gen LLM applications with a generic multi-agent conversation framework. It offers customizable and conversable agents which integrate LLMs, tools, and humans. By automating chat among multiple capable agents, one can easily make them collectively perform tasks autonomously or with human feedback, including tasks that require using tools via code\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "Based on the content of the article, here is a summary:\n",
      "\n",
      "---\n",
      "\n",
      "**Summary of the Article:**\n",
      "\n",
      "AutoGen is an open-source programming framework designed for building AI agents and enhancing collaboration among multiple agents to accomplish tasks. It aims to simplify and expedite the development and research of agentic AI, similar to how PyTorch facilitates deep learning. Key features include:\n",
      "\n",
      "- Agents capable of conversing with one another.\n",
      "- Support for large language models (LLMs) and tool usage.\n",
      "- Workflows that can be autonomous or involve human input.\n",
      "- A framework for multi-agent conversations.\n",
      "\n",
      "The framework enables next-generation LLM applications by providing customizable agents that can integrate LLMs, tools, and human interaction. It automates communication among multiple agents, allowing them to perform tasks collectively, either autonomously or with human feedback, including tasks that require coding tools.\n",
      "\n",
      "---\n",
      "\n",
      "If you need further assistance or another task, let me know! \n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import autogen\n",
    "# create a UserProxyAgent instance named \"user_proxy\"\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    human_input_mode=\"TERMINATE\",\n",
    "    max_consecutive_auto_reply=10,\n",
    "    is_termination_msg=lambda x: x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"),\n",
    "    code_execution_config={\n",
    "        \"work_dir\": \"web\",\n",
    "        \"use_docker\": False,\n",
    "    }, \n",
    "    system_message=\"\"\"Reply TERMINATE if the task has been solved at full satisfaction. Otherwise, reply CONTINUE, or the reason why the task is not solved yet.\"\"\"\n",
    ")\n",
    "\n",
    "# create an AssistantAgent instance named \"assistant\"\n",
    "assistant = autogen.AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    llm_config=llm_config\n",
    ")\n",
    "\n",
    "# create a Task instance named \"task\"\n",
    "#task = \"\"\"Give me a summary of this article: https://apnews.com/article/chemistry-technology-science-biology-europe-9aaa83aa556d4301b8bf15037f45ae87\"\"\"\n",
    "task = \"\"\"Give me a summary of this article: (\"C:\\\\Users\\\\kamathshweta\\\\Downloads\\\\Test2.txt\")\"\"\"\n",
    "#task = \"\"\"Give me a summary of this article: (r\"C:\\Users\\kamathshweta\\Downloads\\Test1.pdf\").\"\"\"\n",
    "\n",
    "# initiate a chat between the user_proxy and the assistant\n",
    "user_proxy.initiate_chat(\n",
    "    assistant,\n",
    "    message=task\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
